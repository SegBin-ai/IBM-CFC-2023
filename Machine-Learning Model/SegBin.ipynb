{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-11 21:23:55--  https://storage.googleapis.com/tf_model_garden/vision/waste_identification_ml/material_model.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.138.128, 142.250.114.128, 142.250.113.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.138.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 521320844 (497M) [application/zip]\n",
      "Saving to: ‘material_model.zip’\n",
      "\n",
      "material_model.zip  100%[===================>] 497.17M   139MB/s    in 3.8s    \n",
      "\n",
      "2023-08-11 21:23:59 (131 MB/s) - ‘material_model.zip’ saved [521320844/521320844]\n",
      "\n",
      "--2023-08-11 21:24:00--  https://storage.googleapis.com/tf_model_garden/vision/waste_identification_ml/material_form_model.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.115.128, 142.250.138.128, 142.251.116.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.115.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 523568744 (499M) [application/zip]\n",
      "Saving to: ‘material_form_model.zip’\n",
      "\n",
      "material_form_model 100%[===================>] 499.31M  85.3MB/s    in 5.8s    \n",
      "\n",
      "2023-08-11 21:24:07 (86.3 MB/s) - ‘material_form_model.zip’ saved [523568744/523568744]\n",
      "\n",
      "--2023-08-11 21:24:08--  https://storage.googleapis.com/tf_model_garden/vision/waste_identification_ml/plastic_types_model.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.113.128, 142.251.116.128, 142.250.114.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.113.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 521268394 (497M) [application/zip]\n",
      "Saving to: ‘plastic_types_model.zip’\n",
      "\n",
      "plastic_types_model 100%[===================>] 497.12M   103MB/s    in 5.7s    \n",
      "\n",
      "2023-08-11 21:24:14 (87.8 MB/s) - ‘plastic_types_model.zip’ saved [521268394/521268394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/tf_model_garden/vision/waste_identification_ml/material_model.zip \n",
    "!wget https://storage.googleapis.com/tf_model_garden/vision/waste_identification_ml/material_form_model.zip \n",
    "!wget https://storage.googleapis.com/tf_model_garden/vision/waste_identification_ml/plastic_types_model.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  material_model.zip\n",
      "   creating: material/saved_model/\n",
      "  inflating: material/saved_model/params.yaml  \n",
      "   creating: material/saved_model/saved_model/\n",
      "  inflating: material/saved_model/saved_model/saved_model.pb  \n",
      "   creating: material/saved_model/saved_model/variables/\n",
      "  inflating: material/saved_model/saved_model/variables/variables.data-00000-of-00001  \n",
      "  inflating: material/saved_model/saved_model/variables/variables.index  \n",
      "   creating: material/saved_model/checkpoint/\n",
      "  inflating: material/saved_model/checkpoint/ckpt-1.data-00000-of-00001  \n",
      "  inflating: material/saved_model/checkpoint/checkpoint  \n",
      "  inflating: material/saved_model/checkpoint/ckpt-1.index  \n",
      "   creating: material/tflite_model/\n",
      "  inflating: material/tflite_model/model.tflite  \n",
      "Archive:  material_form_model.zip\n",
      "   creating: material_form/saved_model/\n",
      "  inflating: material_form/saved_model/params.yaml  \n",
      "   creating: material_form/saved_model/saved_model/\n",
      "  inflating: material_form/saved_model/saved_model/saved_model.pb  \n",
      "   creating: material_form/saved_model/saved_model/variables/\n",
      "  inflating: material_form/saved_model/saved_model/variables/variables.data-00000-of-00001  \n",
      "  inflating: material_form/saved_model/saved_model/variables/variables.index  \n",
      "   creating: material_form/saved_model/checkpoint/\n",
      "  inflating: material_form/saved_model/checkpoint/ckpt-1.data-00000-of-00001  \n",
      "  inflating: material_form/saved_model/checkpoint/checkpoint  \n",
      "  inflating: material_form/saved_model/checkpoint/ckpt-1.index  \n",
      "   creating: material_form/tflite_model/\n",
      "  inflating: material_form/tflite_model/model.tflite  \n",
      "Archive:  plastic_types_model.zip\n",
      "   creating: plastic_type/saved_model/\n",
      "  inflating: plastic_type/saved_model/params.yaml  \n",
      "   creating: plastic_type/saved_model/saved_model/\n",
      "  inflating: plastic_type/saved_model/saved_model/saved_model.pb  \n",
      "   creating: plastic_type/saved_model/saved_model/variables/\n",
      "  inflating: plastic_type/saved_model/saved_model/variables/variables.data-00000-of-00001  \n",
      "  inflating: plastic_type/saved_model/saved_model/variables/variables.index  \n",
      "   creating: plastic_type/saved_model/checkpoint/\n",
      "  inflating: plastic_type/saved_model/checkpoint/ckpt-1.data-00000-of-00001  \n",
      "  inflating: plastic_type/saved_model/checkpoint/checkpoint  \n",
      "  inflating: plastic_type/saved_model/checkpoint/ckpt-1.index  \n",
      "   creating: plastic_type/tflite_model/\n",
      "  inflating: plastic_type/tflite_model/model.tflite  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir material material_form plastic_type\n",
    "unzip material_model.zip -d material/\n",
    "unzip material_form_model.zip -d material_form/\n",
    "unzip plastic_types_model.zip -d plastic_type/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "material\n",
      "material_form\n",
      "material_form_model.zip\n",
      "material_model.zip\n",
      "plastic_type\n",
      "plastic_types_model.zip\n",
      "/home/wsuser/work\n",
      "material\n",
      "material_form\n",
      "material_form_model.zip\n",
      "material_labels.pbtxt\n",
      "material_model.zip\n",
      "plastic_type\n",
      "plastic_types_model.zip\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls\n",
    "pwd\n",
    "touch material_labels.pbtxt\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo '# Mapping of material label ids to string name and human readable string label.\n",
    "# Source: U.S. Environmental Protection Agency (http://shortn/_ktDlFMfXm3)\n",
    "item {\n",
    "id: 1\n",
    "name: \"inorganic_waste\"\n",
    "display_name: \"Soil, bits of concrete and stones\"\n",
    "}\n",
    "item {\n",
    "id: 2\n",
    "name: \"textiles\"\n",
    "display_name: \"Discarded clothing, carpet, sheets and towels\"\n",
    "}\n",
    "item {\n",
    "id: 3\n",
    "name: \"rubber_and_leather\"\n",
    "display_name:\n",
    "  \"Rubber and leather products such as clothing footwear, tires, gaskets and \"\n",
    "  \"furniture\"\n",
    "}\n",
    "item {\n",
    "id: 4\n",
    "name: \"wood\"\n",
    "display_name:\n",
    "  \"Wood products such as cabinets, furniture, and packaging like crates and \"\n",
    "  \"pallets\"\n",
    "}\n",
    "item {\n",
    "id: 5\n",
    "name: \"food\"\n",
    "display_name:\n",
    "  \"Residential, commercial (supermarkets, food whoesale, restaurants, hotels, \"\n",
    "  \"sports venues) and insitutional (hospitals, offices, universities, schools, \"\n",
    "  \"food banks) food waste\"\n",
    "}\n",
    "item {\n",
    "id: 6\n",
    "name: \"plastics\"\n",
    "display_name:\n",
    "  \"Plastic products such as bags, sacks, wraps, cups, bottles, jugs, \"\n",
    "  \"containers, lids, utensils, medical devices and household items\"\n",
    "}\n",
    "item {\n",
    "id: 7\n",
    "name: \"yard_trimmings\"\n",
    "display_name:\n",
    "  \"Grass, leaves and tree and brush trimmings from residential, institutional \"\n",
    "  \"and commercial sources\"\n",
    "}\n",
    "item {\n",
    "id: 8\n",
    "name: \"fiber\"\n",
    "display_name:\n",
    "  \"Cardboard products such as office papers, newspapers, tissue paper, paper \"\n",
    "  \"plates, cups, corrugated boxes, milk cartons, and bags and sacks\"\n",
    "}\n",
    "item {\n",
    "id: 9\n",
    "name: \"glass\"\n",
    "display_name:\n",
    "  \"Glass products such as beer and soft drink bottles, wine and liquor \"\n",
    "  \"bottles, and bottles or jars for food, cosmetics and other products\"\n",
    "}\n",
    "item {\n",
    "id: 10\n",
    "name: \"metals\"\n",
    "display_name:\n",
    "  \"Ferrous (iron and steel), non-ferrous (lead, copper and zinc) and aluminum \"\n",
    "  \"products such as containers, packaging, appliances, batteries, electronics \"\n",
    "  \"and furniture\"\n",
    "}' > material_labels.pbtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: material_labels.pbtxt: No such file or directory\n",
      "mv: cannot stat 'material_labels.pbtxt': No such file or directory\n",
      "bash: line 4: !git: command not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'cat material_labels.pbtxt\\nmv material_labels.pbtxt material/\\n# Clone the tensorflow models repository\\n!git clone --depth 1 https://github.com/tensorflow/models\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcat material_labels.pbtxt\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmv material_labels.pbtxt material/\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Clone the tensorflow models repository\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m!git clone --depth 1 https://github.com/tensorflow/models\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2357\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cat material_labels.pbtxt\\nmv material_labels.pbtxt material/\\n# Clone the tensorflow models repository\\n!git clone --depth 1 https://github.com/tensorflow/models\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat material_labels.pbtxt\n",
    "mv material_labels.pbtxt material/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 3934, done.\u001b[K\n",
      "remote: Counting objects: 100% (3934/3934), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3050/3050), done.\u001b[K\n",
      "remote: Total 3934 (delta 1139), reused 1885 (delta 830), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (3934/3934), 49.69 MiB | 27.73 MiB/s, done.\n",
      "Resolving deltas: 100% (1139/1139), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the tensorflow models repository\n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: sudo: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/wsuser/work/models/research\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting apache-beam\n",
      "  Downloading apache_beam-2.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.6/14.6 MB 73.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from object-detection==0.1) (9.3.0)\n",
      "Requirement already satisfied: lxml in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from object-detection==0.1) (4.9.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from object-detection==0.1) (3.5.2)\n",
      "Collecting Cython\n",
      "  Downloading Cython-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 87.8 MB/s eta 0:00:00\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tf-slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 352.1/352.1 kB 68.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from object-detection==0.1) (1.4.3)\n",
      "Collecting tf-models-official>=2.5.1\n",
      "  Downloading tf_models_official-2.13.1-py2.py3-none-any.whl (2.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 91.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow_io\n",
      "  Downloading tensorflow_io-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.6/28.6 MB 50.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: keras in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from object-detection==0.1) (2.9.0)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 23.5 MB/s eta 0:00:00\n",
      "Collecting sacrebleu<=2.2.0\n",
      "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 kB 37.8 MB/s eta 0:00:00\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
      "Collecting regex\n",
      "  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 771.9/771.9 kB 77.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.1)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting immutabledict\n",
      "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
      "Collecting gin-config\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.3/61.3 kB 23.5 MB/s eta 0:00:00\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pyyaml<5.4.0,>=5.1\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 269.4/269.4 kB 56.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.2/98.2 kB 32.6 MB/s eta 0:00:00\n",
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 88.5 MB/s eta 0:00:00\n",
      "Collecting tensorflow-text~=2.13.0\n",
      "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 91.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.0)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 192.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorflow~=2.13.0\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 524.1/524.1 MB 4.6 MB/s eta 0:00:00\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.96.0-py2.py3-none-any.whl (12.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 90.9 MB/s eta 0:00:00\n",
      "Collecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.6/83.6 kB 28.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 MB 37.0 MB/s eta 0:00:00\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 241.2/241.2 kB 58.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2022.1)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tf-slim->object-detection==0.1) (1.0.0)\n",
      "Collecting objsize<0.7.0,>=0.6.1\n",
      "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting zstandard<1,>=0.18.0\n",
      "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 99.4 MB/s eta 0:00:00\n",
      "Collecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.1/48.1 kB 17.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.42.0)\n",
      "Collecting fasteners<1.0,>=0.3\n",
      "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.3.0)\n",
      "Collecting pymongo<5.0.0,>=3.8.0\n",
      "  Downloading pymongo-4.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (603 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 603.6/603.6 kB 74.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (8.0.0)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.7/89.7 kB 30.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting protobuf<4.24.0,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 304.5/304.5 kB 59.6 MB/s eta 0:00:00\n",
      "Collecting fastavro<2,>=0.23.6\n",
      "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 70.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.0/152.0 kB 45.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.3/140.3 kB 38.7 MB/s eta 0:00:00\n",
      "Collecting cloudpickle~=2.2.1\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting httplib2<0.23.0,>=0.8\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 32.7 MB/s eta 0:00:00\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.7.2.tar.gz (43 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.4/43.4 kB 15.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: cycler>=0.10.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from lvis->object-detection==0.1) (0.11.0)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Downloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.7/61.7 MB 29.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from lvis->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (4.25.0)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.33.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 108.1 MB/s eta 0:00:00\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 120.5/120.5 kB 36.2 MB/s eta 0:00:00\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.33.0)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.11)\n",
      "Collecting bleach\n",
      "  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.5/162.5 kB 35.4 MB/s eta 0:00:00\n",
      "Collecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.4/300.4 kB 60.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.4)\n",
      "Collecting keras\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 101.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (65.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 94.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 440.8/440.8 kB 55.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 22.9/22.9 MB 70.5 MB/s eta 0:00:00\n",
      "Collecting absl-py>=0.2.2\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 37.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.5)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
      "Collecting etils[enp,epath]>=0.9.0\n",
      "  Downloading etils-1.4.1-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.8/135.8 kB 40.9 MB/s eta 0:00:00\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting array-record\n",
      "  Downloading array_record-0.4.1-py310-none-any.whl (3.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 90.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: click in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.0.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
      "Collecting importlib_resources\n",
      "  Downloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: zipp in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
      "Collecting google-auth<3.0.0.dev0,>=1.19.0\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.8/181.8 kB 47.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.1)\n",
      "Collecting grpcio!=1.48.0,<2,>=1.33.1\n",
      "  Downloading grpcio-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 98.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.3)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 106.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.2/78.2 kB 30.8 MB/s eta 0:00:00\n",
      "Collecting protobuf<4.24.0,>=3.20.3\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 88.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
      "Building wheels for collected packages: object-detection, avro-python3, pycocotools, crcmod, dill, hdfs, kaggle, pyyaml, seqeval, docopt, promise\n",
      "  Building wheel for object-detection (setup.py): started\n",
      "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1663230 sha256=8d9edb841ba6e909f3f140aaeec20611ced4627d4018fadce6805d4ad5c3b66f\n",
      "  Stored in directory: /tmp/wsuser/pip-ephem-wheel-cache-u6ylku7b/wheels/99/b8/9a/f376d23a5e5cf4f8032cdccc14516fe7a4153ddfc46b1f25c3\n",
      "  Building wheel for avro-python3 (setup.py): started\n",
      "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44008 sha256=8d160add17cc3bff558a7a5e9fb9b6ccf7ef1a9c958a600deb3c5d26a4675272\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
      "  Building wheel for pycocotools (pyproject.toml): started\n",
      "  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=101701 sha256=fc07e6104ec046e41669212ff51c312029ec8dd212cd88790f27f5f91ab53a6a\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\n",
      "  Building wheel for crcmod (setup.py): started\n",
      "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23339 sha256=879b1d97b521ed50db01915839c18d25f8159762064309fbfd4b0e72a6b0e363\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=5f09ced50a6d1ab0bf099747e8e20b314896a8070a8135a27d921f52430cfb98\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for hdfs (setup.py): started\n",
      "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
      "  Created wheel for hdfs: filename=hdfs-2.7.2-py3-none-any.whl size=34182 sha256=a22468704c305a6753456679ceed9e4a31e84787345692a75de2b92d09000b59\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/ab/39/8e/e1905de9af8ae74911cd3e53e721995cd230816f63776e5825\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110703 sha256=7f2026ba6937c2edb859376a775ed2002b7ae7ccafcfdab229b2b81953776ab0\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/43/4b/fb/736478af5e8004810081a06259f9aa2f7c3329fc5d03c2c412\n",
      "  Building wheel for pyyaml (setup.py): started\n",
      "  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
      "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp310-cp310-linux_x86_64.whl size=44635 sha256=2eacc0917e012d53741bc8f932a5b5e7c61e0923690b74ff75716c0c97495c8b\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/0b/a9/6a/d0a6981a8dbb698845178818642f72ce179f14336908c7df01\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=2129062400e242ba7913651d0ed463de11d16cb9da60de1834cc52b2750c2277\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=5930f2a7d6c11c994c6e1c12ef0f20efb796471c74f5442ca4b04b30b2fbe713\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21502 sha256=0e9a0569789fda8149b680b245881ccde88fa32c61ee788c786f18e4dc87b2f0\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/54/4e/28/3ed0e1c8a752867445bab994d2340724928aa3ab059c57c8db\n",
      "Successfully built object-detection avro-python3 pycocotools crcmod dill hdfs kaggle pyyaml seqeval docopt promise\n",
      "Installing collected packages: webencodings, text-unidecode, py-cpuinfo, libclang, gin-config, flatbuffers, docopt, crcmod, zstandard, uritemplate, toml, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, regex, pyyaml, python-slugify, pyparsing, protobuf, promise, portalocker, orjson, opencv-python-headless, opencv-python, objsize, keras, importlib_resources, immutabledict, grpcio, fasteners, fastavro, etils, dnspython, dill, Cython, contextlib2, colorama, cloudpickle, bleach, avro-python3, absl-py, tf-slim, tensorflow-model-optimization, tensorflow_io, sacrebleu, pymongo, pydot, proto-plus, kaggle, httplib2, hdfs, google-auth, seqeval, oauth2client, google-auth-oauthlib, google-auth-httplib2, google-api-core, apache-beam, tensorboard, pycocotools, lvis, google-api-python-client, array-record, tensorflow-datasets, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "    Found existing installation: tensorflow-io-gcs-filesystem 0.26.0\n",
      "    Uninstalling tensorflow-io-gcs-filesystem-0.26.0:\n",
      "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.26.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.9.0\n",
      "    Uninstalling tensorflow-estimator-2.9.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.9.0\n",
      "    Uninstalling keras-2.9.0:\n",
      "      Successfully uninstalled keras-2.9.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.5.1\n",
      "    Uninstalling dill-0.3.5.1:\n",
      "      Successfully uninstalled dill-0.3.5.1\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.1.0\n",
      "    Uninstalling cloudpickle-2.1.0:\n",
      "      Successfully uninstalled cloudpickle-2.1.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.0.0\n",
      "    Uninstalling absl-py-1.0.0:\n",
      "      Successfully uninstalled absl-py-1.0.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.33.0\n",
      "    Uninstalling google-auth-1.33.0:\n",
      "      Successfully uninstalled google-auth-1.33.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.4\n",
      "    Uninstalling google-auth-oauthlib-0.4.4:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.9.1\n",
      "    Uninstalling tensorboard-2.9.1:\n",
      "      Successfully uninstalled tensorboard-2.9.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.9.3\n",
      "    Uninstalling tensorflow-2.9.3:\n",
      "      Successfully uninstalled tensorflow-2.9.3\n",
      "  Attempting uninstall: tensorflow-text\n",
      "    Found existing installation: tensorflow-text 2.9.0\n",
      "    Uninstalling tensorflow-text-2.9.0:\n",
      "      Successfully uninstalled tensorflow-text-2.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 1.6.5 requires protobuf<=3.20.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "pytorch-lightning 1.6.5 requires PyYAML>=5.4, but you have pyyaml 5.3.1 which is incompatible.\n",
      "onnx 1.12.0 requires protobuf<=3.20.1,>=3.12.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "autoai-ts-libs 2.0.13 requires tensorflow<2.13,>=2.7.0; python_version >= \"3.9\", but you have tensorflow 2.13.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed Cython-3.0.0 absl-py-1.4.0 apache-beam-2.49.0 array-record-0.4.1 avro-python3-1.10.2 bleach-6.0.0 cloudpickle-2.2.1 colorama-0.4.6 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 etils-1.4.1 fastavro-1.8.2 fasteners-0.18 flatbuffers-23.5.26 gin-config-0.5.0 google-api-core-2.11.1 google-api-python-client-2.96.0 google-auth-2.22.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-1.0.0 grpcio-1.57.0 hdfs-2.7.2 httplib2-0.22.0 immutabledict-3.0.0 importlib_resources-6.0.1 kaggle-1.5.16 keras-2.13.1 libclang-16.0.6 lvis-0.5.3 oauth2client-4.1.3 object-detection-0.1 objsize-0.6.1 opencv-python-4.8.0.76 opencv-python-headless-4.8.0.76 orjson-3.9.4 portalocker-2.7.0 promise-2.3 proto-plus-1.22.3 protobuf-3.20.3 py-cpuinfo-9.0.0 pycocotools-2.0.6 pydot-1.4.2 pymongo-4.4.1 pyparsing-2.4.7 python-slugify-8.0.1 pyyaml-5.3.1 regex-2023.8.8 sacrebleu-2.2.0 seqeval-1.2.2 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-datasets-4.9.2 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.33.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.13.0 tensorflow_io-0.33.0 text-unidecode-1.3 tf-models-official-2.13.1 tf-slim-1.1.0 toml-0.10.2 uritemplate-4.1.1 webencodings-0.5.1 zstandard-0.21.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo apt install -y protobuf-compiler\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibmcloudant in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (0.4.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibmcloudant) (2.8.2)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core==3.16.7 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibmcloudant) (3.16.7)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibmcloudant) (2.4.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.20 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibmcloudant) (2.31.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cloud-sdk-core==3.16.7->ibmcloudant) (1.26.11)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.5.3->ibmcloudant) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3.0,>=2.20->ibmcloudant) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3.0,>=2.20->ibmcloudant) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3.0,>=2.20->ibmcloudant) (2023.7.22)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (3.16.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cloud-sdk-core) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cloud-sdk-core) (2.31.0)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.4.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cloud-sdk-core) (2.4.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cloud-sdk-core) (1.26.11)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.5.3->ibm-cloud-sdk-core) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->ibm-cloud-sdk-core) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->ibm-cloud-sdk-core) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->ibm-cloud-sdk-core) (3.3)\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from opencv-python-headless) (1.23.1)\n",
      "Requirement already satisfied: pymongo in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (4.4.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pymongo) (2.4.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (9.3.0)\n",
      "Requirement already satisfied: paho-mqtt in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (3.5.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.23.1)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (1.57.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: tensorflow_hub in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow_hub) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from tensorflow_hub) (1.23.1)\n",
      "Collecting pyvirtualdisplay\n",
      "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pyvirtualdisplay\n",
      "Successfully installed pyvirtualdisplay-3.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install ibmcloudant\n",
    "pip install ibm-cloud-sdk-core\n",
    "pip install opencv-python-headless\n",
    "pip install pymongo\n",
    "pip install Pillow\n",
    "pip install paho-mqtt\n",
    "pip install matplotlib\n",
    "pip install numpy\n",
    "pip install tensorflow\n",
    "pip install tensorflow_hub\n",
    "pip install pyvirtualdisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Xvfb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyvirtualdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Display\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Start a virtual display\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m display \u001b[38;5;241m=\u001b[39m \u001b[43mDisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisible\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m display\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Your existing code that uses OpenCV (cv2)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pyvirtualdisplay/display.py:54\u001b[0m, in \u001b[0;36mDisplay.__init__\u001b[0;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, retries, extra_args, manage_global_env, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbgcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbgcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_xauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_xauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# check_startup=check_startup,\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanage_global_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanage_global_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pyvirtualdisplay/xvfb.py:44\u001b[0m, in \u001b[0;36mXvfbDisplay.__init__\u001b[0;34m(self, size, color_depth, bgcolor, use_xauth, fbdir, dpi, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fbdir \u001b[38;5;241m=\u001b[39m fbdir\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dpi \u001b[38;5;241m=\u001b[39m dpi\n\u001b[0;32m---> 44\u001b[0m \u001b[43mAbstractDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPROGRAM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_xauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_xauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanage_global_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanage_global_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pyvirtualdisplay/abstractdisplay.py:85\u001b[0m, in \u001b[0;36mAbstractDisplay.__init__\u001b[0;34m(self, program, use_xauth, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_wfd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retries_current \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 85\u001b[0m helptext \u001b[38;5;241m=\u001b[39m \u001b[43mget_helptext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_displayfd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-displayfd\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m helptext\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_displayfd:\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pyvirtualdisplay/util.py:13\u001b[0m, in \u001b[0;36mget_helptext\u001b[0;34m(program)\u001b[0m\n\u001b[1;32m      6\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [program, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-help\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# py3.7+\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# p = subprocess.run(cmd, capture_output=True)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# stderr = p.stderr\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# py3.6 also\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m _, stderr \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mcommunicate()\n\u001b[1;32m     21\u001b[0m helptext \u001b[38;5;241m=\u001b[39m stderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/subprocess.py:1847\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1846\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1847\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Xvfb'"
     ]
    }
   ],
   "source": [
    "# export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "# Import necessary libraries\n",
    "from ibmcloudant.cloudant_v1 import CloudantV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import cv2\n",
    "import pymongo\n",
    "import datetime\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from pymongo import MongoClient\n",
    "import paho.mqtt.client as mqtt\n",
    "import urllib.parse\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "import ssl\n",
    "from urllib.request import urlopen\n",
    "import uuid\n",
    "import socket\n",
    "\n",
    "# Set MQTT broker information (using Mosquitto broker)\n",
    "mqtt_broker = \"localhost\"  # Replace with the address of your Mosquitto broker\n",
    "mqtt_port = 1883  # Default MQTT port\n",
    "mqtt_topic = \"waste_detection\"  # Replace with the desired MQTT topic\n",
    "\n",
    "# Create an MQTT client instance\n",
    "mqtt_client = mqtt.Client()\n",
    "\n",
    "# Connect to the MQTT broker\n",
    "mqtt_client.connect(mqtt_broker, mqtt_port)\n",
    "\n",
    "def get_mac_address():\n",
    "    try:\n",
    "        mac_address = uuid.UUID(int=uuid.getnode()).hex[-12:]\n",
    "    except Exception as e:\n",
    "        print(\"Error getting MAC address:\", e)\n",
    "        return None\n",
    "\n",
    "    return \":\".join([mac_address[i:i+2] for i in range(0, 12, 2)])\n",
    "\n",
    "\n",
    "# Update the Cloudant credentials\n",
    "credentials = {\n",
    "    \"apikey\": \"tmSRIS_CQp3vRDKNqaRgMjaGTMV9MNkYvmKlhejpMKxG\",\n",
    "    \"url\": \"https://d66297a5-6c29-485c-840e-5903af9a45f7-bluemix.cloudantnosqldb.appdomain.cloud\",\n",
    "    \"username\": \"apikey-v2-tuy7g6x55ttl869okke0el42d5ljflybly5txrxy3is\"\n",
    "}\n",
    "\n",
    "# Create an IAM Authenticator\n",
    "authenticator = IAMAuthenticator(credentials['apikey'])\n",
    "\n",
    "# Create a Cloudant client\n",
    "client = CloudantV1(authenticator=authenticator)\n",
    "client.set_service_url(credentials['url'])\n",
    "\n",
    "# Specify the database name\n",
    "database_name = \"test\"  # Replace 'your_database_name' with the desired database name\n",
    "\n",
    "# Get the existing databases to check if the specified database exists\n",
    "response = client.get_all_dbs().get_result()\n",
    "if database_name not in response:\n",
    "    # If the specified database doesn't exist, create it\n",
    "    response = client.put_database(db=database_name).get_result()\n",
    "\n",
    "# # Escape username and password\n",
    "# username = urllib.parse.quote_plus('av34')\n",
    "# password = urllib.parse.quote_plus('test12345')\n",
    "\n",
    "# # Construct the MongoDB URI with escaped username and password\n",
    "# uri = f\"mongodb+srv://{username}:{password}@cluster0.w52bjm1.mongodb.net/\"\n",
    "\n",
    "# # Establish a connection to MongoDB\n",
    "# client = MongoClient(uri)\n",
    "\n",
    "# # Create or access the database\n",
    "# db = client['SegBin']  # Replace 'my_database' with the desired database name\n",
    "\n",
    "# # Create or access the collection\n",
    "# collection = db['test']  # Replace 'my_collection' with the desired collection name\n",
    "\n",
    "# Rest of the code...\n",
    "\n",
    "\n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open webcam\")\n",
    "        return\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image\")\n",
    "        return\n",
    "    cv2.imshow(\"Captured Image\", frame)\n",
    "    cv2.imwrite(\"Science_plastic.jpg\", frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "ALL_MODELS = {\n",
    "'material_model' : 'material/saved_model/saved_model'\n",
    "# 'material_form_model' : '/Users/aadityavoruganti/SegBin.ai/Image-classfication/Image-classfication Backend/material_form/saved_model/saved_model/',\n",
    "# 'plastic_model' : '/Users/aadityavoruganti/SegBin.ai/Image-classfication/Image-classfication Backend/plastic_type/saved_model/saved_model/'\n",
    "}\n",
    "\n",
    "def normalize_image(image,\n",
    "                    offset=(0.485, 0.456, 0.406),\n",
    "                    scale=(0.229, 0.224, 0.225)):\n",
    "  with tf.name_scope('normalize_image'):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    offset = tf.constant(offset)\n",
    "    offset = tf.expand_dims(offset, axis=0)\n",
    "    offset = tf.expand_dims(offset, axis=0)\n",
    "    image -= offset\n",
    "\n",
    "    scale = tf.constant(scale)\n",
    "    scale = tf.expand_dims(scale, axis=0)\n",
    "    scale = tf.expand_dims(scale, axis=0)\n",
    "    image /= scale\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path, target_size=(1024, 512)):\n",
    "    image = None\n",
    "    if path.startswith('http'):\n",
    "        response = urlopen(path)\n",
    "        image_data = response.read()\n",
    "        image_data = BytesIO(image_data)\n",
    "        image = Image.open(image_data)\n",
    "    else:\n",
    "        image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "    image = image.resize(target_size)\n",
    "    if image.mode == 'RGBA':\n",
    "        image = image.convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "    return image_np_expanded.astype(np.uint8)\n",
    "\n",
    "def build_inputs_for_segmentation(image):\n",
    "    image = normalize_image(image)\n",
    "    return image\n",
    "\n",
    "model_display_name = 'material_model' # @param ['material_model','material_form_model','plastic_model']\n",
    "model_handle = ALL_MODELS[model_display_name]\n",
    "\n",
    "print('Selected model:'+ model_display_name)\n",
    "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))\n",
    "\n",
    "if model_display_name == 'material_model':\n",
    "  PATH_TO_LABELS = 'material/material_labels.pbtxt'\n",
    "# elif model_display_name == 'material_form_model':\n",
    "#   PATH_TO_LABELS = '/Users/aadityavoruganti/SegBin.ai/Image-classfication/Image-classfication Backend/models/official/projects/waste_identification_ml/pre_processing/config/data/material_form_labels.pbtxt'\n",
    "# elif model_display_name == 'plastic_model':\n",
    "#   PATH_TO_LABELS = '/Users/aadityavoruganti/SegBin.ai/Image-classfication/Image-classfication Backend/models/official/projects/waste_identification_ml/pre_processing/config/data/plastic_type_labels.pbtxt'\n",
    "\n",
    "print('Labels selected for',model_display_name)\n",
    "print('\\n')\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "category_index\n",
    "\n",
    "# Define the condensed labels mapping\n",
    "condensed_labels = {\n",
    "    1: 'Soil, bits of concrete and stones',\n",
    "    2: 'Discarded clothing, carpet, sheets and towels',\n",
    "    3: 'Rubber and leather products such as clothing footwear, tires, gaskets and furniture',\n",
    "    4: 'Wood products such as cabinets, furniture, and packaging like crates and pallets',\n",
    "    5: 'Residential, commercial (supermarkets, food wholesale, restaurants, hotels, sports venues) and institutional (hospitals, offices, universities, schools, food banks) food waste',\n",
    "    6: 'Plastic products such as bags, sacks, wraps, cups, bottles, jugs, containers, lids, utensils, medical devices and household items',\n",
    "    7: 'Grass, leaves and tree and brush trimmings from residential, institutional and commercial sources',\n",
    "    8: 'Cardboard products such as office papers, newspapers, tissue paper, paper plates, cups, corrugated boxes, milk cartons, and bags and sacks',\n",
    "    9: 'Glass products such as beer and soft drink bottles, wine and liquor bottles, and bottles or jars for food, cosmetics and other products',\n",
    "    10: 'Ferrous (iron and steel), non-ferrous (lead, copper and zinc) and aluminum products such as containers, packaging, appliances, batteries, electronics and furniture'\n",
    "}\n",
    "\n",
    "\n",
    "print('loading model...')\n",
    "hub_model = hub.load(model_handle)\n",
    "print('model loaded!')\n",
    "\n",
    "while True:\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Failed to open webcam\")\n",
    "            exit()\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture image\")\n",
    "                break\n",
    "            cv2.imshow(\"Webcam\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "                cv2.imwrite(\"Science_plastic.jpg\", frame)\n",
    "                print(\"Image captured!\")\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    IMAGES_FOR_TEST = {\n",
    "    'TestImage' : 'Science_plastic.jpg'\n",
    "    } \n",
    "\n",
    "    selected_image = \"TestImage\" #@param [\"Image1\", \"TestImage\"]\n",
    "    flip_image_horizontally = False #@param {type:\"boolean\"}\n",
    "    convert_image_to_grayscale = False #@param {type:\"boolean\"}\n",
    "\n",
    "    image_path = IMAGES_FOR_TEST[selected_image]\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    if(flip_image_horizontally):\n",
    "        image_np[0] = np.fliplr(image_np[0]).copy()\n",
    "\n",
    "    if(convert_image_to_grayscale):\n",
    "        image_np[0] = np.tile(\n",
    "        np.mean(image_np[0], 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    print('min:',np.min(image_np[0]), 'max:', np.max(image_np[0]))\n",
    "    plt.figure(figsize=(24,32))\n",
    "    plt.imshow(image_np[0])\n",
    "    # plt.savefig('figurepreprocess.png') \n",
    "    # plt.show()\n",
    "    plt.close()  # Close the figure\n",
    "\n",
    "    hub_model_fn = hub_model.signatures[\"serving_default\"]\n",
    "    height=hub_model_fn.structured_input_signature[1]['inputs'].shape[1]\n",
    "    width = hub_model_fn.structured_input_signature[1]['inputs'].shape[2]\n",
    "    input_size = (height, width)\n",
    "    print(input_size)\n",
    "\n",
    "    image_np_cp = cv2.resize(image_np[0], input_size[::-1], interpolation = cv2.INTER_AREA)\n",
    "    image_np = build_inputs_for_segmentation(image_np_cp)\n",
    "    image_np = tf.expand_dims(image_np, axis=0)\n",
    "    image_np.get_shape()\n",
    "\n",
    "    plt.figure(figsize=(24,32))\n",
    "    plt.imshow(image_np[0])\n",
    "    # plt.savefig('figureprocessed.png')\n",
    "    # plt.show()\n",
    "    plt.close()  # Close the figure\n",
    "\n",
    "    results = hub_model_fn(image_np)\n",
    "    result = {key:value.numpy() for key,value in results.items()}\n",
    "    print(result.keys())\n",
    "\n",
    "    label_id_offset = 0\n",
    "    min_score_thresh =0.6\n",
    "    use_normalized_coordinates=True\n",
    "\n",
    "    if use_normalized_coordinates:\n",
    "        result['detection_boxes'][0][:,[0,2]] /= height\n",
    "        result['detection_boxes'][0][:,[1,3]] /= width\n",
    "\n",
    "    if 'detection_masks' in result:\n",
    "        detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n",
    "        detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes,\n",
    "                    image_np.shape[1], image_np.shape[2])\n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                            np.uint8)\n",
    "        result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "\n",
    "\n",
    "\n",
    "    mask_count = np.sum(result['detection_scores'][0] >= min_score_thresh)\n",
    "    print('Total number of objects found are:', mask_count)\n",
    "    mask = np.zeros_like(detection_masks_reframed[0])\n",
    "    for i in range(mask_count):\n",
    "        if result['detection_scores'][0][i] >= min_score_thresh:\n",
    "            mask += detection_masks_reframed[i]\n",
    "\n",
    "    mask = tf.clip_by_value(mask, 0,1)\n",
    "    plt.figure(figsize=(24,32))\n",
    "    plt.imshow(mask,cmap='gray')\n",
    "    # plt.savefig('figuremask.png')\n",
    "    # plt.show()\n",
    "    plt.close()  # Close the figure\n",
    "\n",
    "    detected_labels = []\n",
    "    for i in range(mask_count):\n",
    "        if result['detection_scores'][0][i] >= min_score_thresh:\n",
    "            label = category_index[result['detection_classes'][0][i] + label_id_offset]['name']\n",
    "            detected_labels.append(label)\n",
    "\n",
    "    detection_scores = result['detection_scores'][0]\n",
    "    detected_scores = detection_scores[:mask_count]\n",
    "\n",
    "    total_score = np.sum(detected_scores)\n",
    "    accuracy_percentages = [score / total_score * 100 for score in detected_scores]\n",
    "\n",
    "    for label, accuracy in zip(detected_labels, accuracy_percentages):\n",
    "        print(f\"Detected object: {label}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Get the current date and time\n",
    "    current_datetime = datetime.datetime.now()\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        mac_address = get_mac_address()\n",
    "\n",
    "    # ... Previous code ...\n",
    "\n",
    "    # Convert datetime to string representation\n",
    "    current_datetime_str = current_datetime.isoformat()\n",
    "\n",
    "    # Create a dictionary for the JSON packet\n",
    "    json_packet = {\n",
    "        'mac_address': mac_address,\n",
    "        'timestamp': current_datetime_str,\n",
    "        'detected_objects': []\n",
    "    }\n",
    "\n",
    "    # Define the labels for each waste category\n",
    "    Category1_Labels = [\n",
    "        'Soil, bits of concrete and stones',\n",
    "        'Grass, leaves and tree and brush trimmings',\n",
    "        'Residential, commercial and institutional food waste'\n",
    "    ]\n",
    "\n",
    "    Category2_Labels = [\n",
    "        'Cardboard products such as office papers, newspapers, tissue paper, paper plates, cups, corrugated boxes, milk cartons, and bags and sacks'\n",
    "        # Add more labels for Category 2 as needed\n",
    "    ]\n",
    "\n",
    "    Category3_Labels = [\n",
    "        'Plastic products such as bags, sacks, wraps, cups, bottles, jugs, containers, lids, utensils, medical devices and household items',\n",
    "        'Rubber and leather products such as clothing footwear, tires, gaskets and furniture'\n",
    "        # Add more labels for Category 3 as needed\n",
    "    ]\n",
    "\n",
    "    Category4_Labels = [\n",
    "        'Wood products such as cabinets, furniture, and packaging like crates and pallets',\n",
    "        'Discarded clothing, carpet, sheets and towels',\n",
    "        'Glass products such as beer and soft drink bottles, wine and liquor bottles, and bottles or jars for food, cosmetics and other products',\n",
    "        'Ferrous (iron and steel), non-ferrous (lead, copper and zinc) and aluminum products such as containers, packaging, appliances, batteries, electronics and furniture'\n",
    "        # Add more labels for Category 4 as needed\n",
    "    ]\n",
    "\n",
    "    # Inside the for loop for detected labels and accuracy\n",
    "    for i in range(mask_count):\n",
    "        if result['detection_scores'][0][i] >= min_score_thresh:\n",
    "            label_id = result['detection_classes'][0][i] + label_id_offset\n",
    "            accuracy = accuracy_percentages[i]\n",
    "\n",
    "            # Get the corresponding condensed label or use 'Unknown' if not found\n",
    "            condensed_label = condensed_labels.get(label_id, 'Unknown')\n",
    "            print(f\"Detected object: {condensed_label}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "            # Determine the waste category based on the detected label\n",
    "            waste_category = None\n",
    "            if condensed_label in Category1_Labels:\n",
    "                waste_category = 'Category 1: Organic and Biodegradable Waste'\n",
    "            elif condensed_label in Category2_Labels:\n",
    "                waste_category = 'Category 2: Paper and Cardboard Waste'\n",
    "            elif condensed_label in Category3_Labels:\n",
    "                waste_category = 'Category 3: Plastics and Rubber Waste'\n",
    "            elif condensed_label in Category4_Labels:\n",
    "                waste_category = 'Category 4: Metal and Glass Waste'\n",
    "\n",
    "            if waste_category:\n",
    "                print(f\"Waste Category: {waste_category}\")\n",
    "\n",
    "            # Create a dictionary for the detected object\n",
    "            detected_object = {\n",
    "                'label': condensed_label,\n",
    "                'accuracy': accuracy,\n",
    "                'waste_category': waste_category\n",
    "            }\n",
    "\n",
    "            # Append the detected object to the JSON packet\n",
    "            json_packet['detected_objects'].append(detected_object)\n",
    "\n",
    "    # ... Rest of the code ...\n",
    "\n",
    "\n",
    "\n",
    "    # # Insert the JSON packet into the collection\n",
    "    # collection.insert_one(json_packet)\n",
    "\n",
    "    # Push the JSON packet to the database\n",
    "    response = client.post_document(db=database_name, document=json_packet).get_result()\n",
    "\n",
    "    # Publish the JSON packet to the MQTT topic\n",
    "    mqtt_payload = json.dumps(json_packet)  # Convert the JSON packet to a string\n",
    "    mqtt_client.publish(mqtt_topic, mqtt_payload)\n",
    "\n",
    "    # Print the response to verify if the document was successfully inserted\n",
    "    print(response)\n"
   ]
  }
